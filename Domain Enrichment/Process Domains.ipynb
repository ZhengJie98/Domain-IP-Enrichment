{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccdf0a7",
   "metadata": {},
   "source": [
    "### Questions / Todo List\n",
    "\n",
    "1. What do i do with the download_page(url) function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561b49c",
   "metadata": {},
   "source": [
    "## Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167928d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crtsh import crtshAPI ## search certificate /\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "from waybackpy import WaybackMachineCDXServerAPI ## search historical copies of website\n",
    "import socket\n",
    "import dns.resolver\n",
    "import whois # query and response protocol that is often used for querying databases that store registered domain names.\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0d567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: #0 - ï»¿domains\n",
      "exception triggered\n",
      "download_archieved_page exception triggered\n",
      "Processing: #1 - www.apple.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puddi\\AppData\\Local\\Temp\\ipykernel_11300\\1395310461.py:113: DeprecationWarning: please use dns.resolver.resolve() instead\n",
      "  nameservers = dns.resolver.query(domain_name, 'NS')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: #2 - www.facebook.com\n",
      "Processing: #3 - www.amazon.com\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "from crtsh import crtshAPI ## search certificate /\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "from waybackpy import WaybackMachineCDXServerAPI ## search historical copies of website\n",
    "import socket\n",
    "import dns.resolver\n",
    "import whois # query and response protocol that is often used for querying databases that store registered domain names.\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def download_page(url):\n",
    "\n",
    "    #TODO: Integrate shot-scraper CLI calls\n",
    "    print(\"current download_page url:\",url)\n",
    "    !shot-scraper {url}\n",
    "    print(\"download page completed\")\n",
    "\n",
    "    return 0\n",
    "\n",
    "# Returns URL of latest archive page, timestamp of latest archive page\n",
    "def download_archived_page(url):\n",
    "\n",
    "    try:\n",
    "        user_agent = \"Mozilla/5.0 (Windows NT 5.1; rv:40.0) Gecko/20100101 Firefox/40.0\"\n",
    "        cdx_api = WaybackMachineCDXServerAPI(url, user_agent)\n",
    "\n",
    "        newest = cdx_api.newest()\n",
    "\n",
    "        return [newest.archive_url, newest.timestamp]\n",
    "\n",
    "    except:\n",
    "        print(\"download_archieved_page exception triggered\")\n",
    "\n",
    "        return ['', '']\n",
    "\n",
    "# Returns Subject CN, SAN, Issuer Details, Issued Date, Earliest Issue Date of the first cert, Number of Certs\n",
    "def download_cert(domain_name):\n",
    "\n",
    "    if not os.path.exists(\"downloaded_certs\"):\n",
    "            os.makedirs(\"downloaded_certs\")\n",
    "        \n",
    "    try:\n",
    "        cert_json = crtshAPI().search(domain_name)\n",
    "#         print(cert_json)\n",
    "        \n",
    "#         print(cert_json[len(cert_json)-1])\n",
    "        \n",
    "        \n",
    "        with open(\"downloaded_certs/\" + domain_name + \".json\", \"w\") as outfile:\n",
    "            json.dump(cert_json, outfile)\n",
    "\n",
    "        return [cert_json[0]['common_name'], cert_json[0]['name_value'], cert_json[0]['issuer_name'], cert_json[0]['not_before'], cert_json[len(cert_json)-1]['not_before'], len(cert_json)]\n",
    "\n",
    "    except:\n",
    "\n",
    "        print(\"exception triggered\")\n",
    "        return ['', '', '', '', '', '']\n",
    "\n",
    "\n",
    "\n",
    "# Returns Unique CNs, Set of CNs, Unique Issuers, Set of Issuers, Unique AltName Values, Min of AltName Count, Max of AltName Count\n",
    "def process_downloaded_cert(domain_name):\n",
    "\n",
    "    try:\n",
    "        # Opening JSON file\n",
    "        f = open(\"downloaded_certs/\" + domain_name + \".json\")\n",
    "        data = json.load(f)\n",
    "\n",
    "        SubjectCN_set = set()\n",
    "        Issuer_set = set()\n",
    "        SerialNo_set = set()\n",
    "        AltName_set = set()\n",
    "        AltName_count_min = 99999\n",
    "        AltName_count_max = 0\n",
    "\n",
    "        if (len(data) == 0):\n",
    "            return ['', '', '', '', '', '', '']\n",
    "\n",
    "\n",
    "        for i in data:\n",
    "            #print(i)\n",
    "\n",
    "            SubjectCN_set.add(i[\"common_name\"])\n",
    "            Issuer_set.add(i[\"issuer_name\"])\n",
    "            SerialNo_set.add(i[\"serial_number\"])\n",
    "            AltName_set.add(i[\"name_value\"])\n",
    "\n",
    "\n",
    "            NumOfAltNamesInside = (i[\"name_value\"].count(\"\\n\"))+1\n",
    "            if (NumOfAltNamesInside < AltName_count_min):\n",
    "                AltName_count_min = NumOfAltNamesInside\n",
    "\n",
    "            if (NumOfAltNamesInside > AltName_count_max):\n",
    "                AltName_count_max = NumOfAltNamesInside\n",
    "\n",
    "        # Closing file\n",
    "        f.close()\n",
    "\n",
    "        return [len(SubjectCN_set), SubjectCN_set, len(Issuer_set), Issuer_set, len(AltName_set), AltName_count_min, AltName_count_max]\n",
    "\n",
    "    except:\n",
    "        return ['', '', '', '', '', '', '']\n",
    "\n",
    "# Returns CNAME, A IPs, Nameservers\n",
    "def get_dns_info(domain_name):\n",
    "\n",
    "    try:\n",
    "        dns_info = socket.gethostbyname_ex(domain_name)\n",
    "        nameservers = dns.resolver.query(domain_name, 'NS')\n",
    "        nameserver_list = [i.to_text() for i in nameservers]\n",
    "\n",
    "        return [dns_info[1], dns_info[2], nameserver_list]\n",
    "\n",
    "    except:\n",
    "\n",
    "        return [[], [], []]\n",
    "\n",
    "\n",
    "# Returns Registra, Name, Org, Created Date, Updated Date\n",
    "def get_domain_whois_info(domain_name):\n",
    "\n",
    "    try:\n",
    "        w = whois.whois(domain_name)\n",
    "        with open(\"downloaded_whois/\" + domain_name + \".txt\", \"w\") as outfile:\n",
    "            outfile.write(str(w.text))\n",
    "\n",
    "        return [w.registrar, w.name, w.org, w.creation_date, w.updated_date]\n",
    "\n",
    "    except:\n",
    "\n",
    "        return ['', '', '', '', '']\n",
    "\n",
    "\n",
    "\n",
    "with open('to_process.csv', newline='') as inputfile:\n",
    "    with open('output_certVariations.csv', 'w', newline='') as outputfile:\n",
    "        domain_list = csv.reader(inputfile, delimiter=',')\n",
    "        output_writer = csv.writer(outputfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        for row in domain_list:\n",
    "            print(\"Processing: #\" + str(counter) + \" - \" + row[0])\n",
    "\n",
    "            cert_list = download_cert(row[0])\n",
    "            archivedpage_list = download_archived_page(row[0])\n",
    "            dns_list = get_dns_info(row[0])\n",
    "            whois_list = get_domain_whois_info(row[0])\n",
    "\n",
    "            cert_variations = process_downloaded_cert(row[0])\n",
    "\n",
    "#             output_writer.writerow(row + [datetime.datetime.now()] + cert_list + archivedpage_list + dns_list + whois_list)\n",
    "\n",
    "            output_writer.writerow(row + [datetime.datetime.now()] + cert_variations)\n",
    "\n",
    "            outputfile.flush()\n",
    "\n",
    "            counter += 1\n",
    "            #time.sleep(4)\n",
    "\n",
    "\n",
    "\n",
    "print(\"completed\")\n",
    "exit(0)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
