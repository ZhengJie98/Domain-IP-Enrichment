{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3b892e",
   "metadata": {},
   "source": [
    "### Changelog \n",
    "\n",
    "- Separating **process_iplist()** output from VT calls to folders (todays_date)\n",
    "- changed output of **process_json()** FROM \"_parsed-combined\" to todays_date_parsed-combined in EACH RESPECTIVE FOLDER "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d748134",
   "metadata": {},
   "source": [
    "### Flow\n",
    "\n",
    "1. User edits and feeds ip.csv\n",
    "2. **process_iplist()** reads each and calls VT api \n",
    "3. Responses are stored in **\"downloaded_vtresponse\"** and seperated into folders by **respective dates** (DDMMYYYY)\n",
    "4. **process_json()** reads jsons in each folder and generates a compilation for that day in each folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663865c",
   "metadata": {},
   "source": [
    "### Questions / Todo List\n",
    "\n",
    "**Update** \n",
    "\n",
    "I have managed to get the scripts running from jupyter notebook but have the following questions\n",
    "\n",
    "(a) Receiving (via a web interface) either an individual or list of domais / IP addresses --> currently it's fed via CSV, should i create a front-end for people to upload their files?\n",
    "\n",
    "(b) Storing list of domains / IP address into a queue based list --> Is this the back-end of things? That is to say, this script runs in the back-end and whenever files come in from front-end it'll trigger the script?\n",
    "\n",
    "(c) Carryout enrichment --> Where does this \"processed in the previous X days\" come from? From what i understand, should i create a check such that when new information comes in, it will look at previous histories when the IP/Domain was checked, and continue / stop accordingly? \n",
    "\n",
    "(d) storing responses in disk and extracting subset into DB --> is there a specific subset you'd like? DB-wise I would prefer to try NoSQL as i have no experience with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca118d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= process_iplist() START =======\n",
      "Processing: #1 - 34.123.194.52\n",
      "file has been processed on 22022023 which is <7 days ago, will skip API call\n",
      "Processing: #2 - 77.120.241.130\n",
      "file has been processed on 22022023 which is <7 days ago, will skip API call\n",
      "Processing: #3 - 80.253.95.99\n",
      "file has been processed on 22022023 which is <7 days ago, will skip API call\n",
      "Processing: #4 - 1.1.1.1\n",
      "======= process_iplist() END ======= \n",
      "\n",
      "\n",
      "======= process_json_folder() START =======\n",
      "Processing: downloaded_vtresponse/23022023\\1.1.1.1.json\n",
      "country not found with exception: 'country'\n",
      "image not found with exception: 'image'\n",
      "new_row[key]: 2023-02-23 16:59:19.771463+08:00\n",
      "new_row: {'ip_address': '1.1.1.1', 'whois_date': datetime.datetime(2023, 2, 14, 3, 46, 44), 'last_analysis_date': datetime.datetime(2023, 2, 23, 13, 22, 18), 'reputation': 89, 'last_analysis_stats': {'harmless': 75, 'malicious': 1, 'suspicious': 0, 'undetected': 12, 'timeout': 0}, 'total_votes': {'harmless': 73, 'malicious': 12}, 'as_owner': 'CLOUDFLARENET', 'country': '', 'asn': 13335, 'image': '', 'processed_date': datetime.datetime(2023, 2, 23, 16, 59, 19, 771463, tzinfo=<DstTzInfo 'Singapore' +08+8:00:00 STD>)}\n",
      "======= process_json_folder() END ======= \n",
      "\n",
      "\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import hashlib\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from dateutil import tz\n",
    "import pytz\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "json_template_ip = {\n",
    "    \n",
    "    \"ip_address\": \"\",\n",
    "    \"whois_date\": \"\",\n",
    "    \"last_analysis_date\": \"\",\n",
    "    \"reputation\": \"\",\n",
    "    \"last_analysis_stats\": \"\",\n",
    "    \"total_votes\": \"\",\n",
    "    \"as_owner\": \"\",\n",
    "    \"country\": \"\",\n",
    "    \"asn\": \"\",\n",
    "    \"image\":\"\",\n",
    "    \"processed_date\":\"\"\n",
    "       \n",
    "}\n",
    "\n",
    "API_KEY = '0d9fdb6e32d74b9d12e3d894309531838c3aabe8d66b049fd3a7976fbedf2c68'  #@param  {type: \"string\"}\n",
    "\n",
    "client = MongoClient('localhost',27017)\n",
    "db = client['d_ip_enrich']\n",
    "    \n",
    "\n",
    "\n",
    "def process_iplist(filename_to_process, columnIndex, x_days_ago):\n",
    "    \n",
    "    print(\"======= process_iplist() START =======\")\n",
    "    \n",
    "    # TODO: Make generalised and incorporate timestamp in foldername\n",
    "    now = datetime.datetime.now()\n",
    "    dt_string = now.strftime(\"%d%m%Y\")\n",
    "    d = datetime.timedelta(days = x_days_ago)\n",
    "    deducted_date = (now - d).strftime(\"%d%m%Y\")\n",
    "    \n",
    "    with open(filename_to_process + \".csv\", newline='') as inputfile:\n",
    "\n",
    "        if not os.path.exists(\"downloaded_vtresponse\"):\n",
    "                os.makedirs(\"downloaded_vtresponse\")\n",
    "\n",
    "        with open(filename_to_process + \"_tracker_\" + dt_string + \".csv\", 'w', newline='') as outputfile:\n",
    "            \n",
    "            ip_list = csv.reader(inputfile, delimiter=',')\n",
    "            output_writer = csv.writer(outputfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "            counter = 0\n",
    "\n",
    "            for row in ip_list:\n",
    "                \n",
    "                if counter == 0:\n",
    "                    output_writer.writerow(row + [\"Time Run\"])\n",
    "                    outputfile.flush()\n",
    "                    counter += 1\n",
    "                    continue\n",
    "\n",
    "                print(\"Processing: #\" + str(counter) + \" - \" + row[columnIndex])\n",
    "                \n",
    "                # Check if IP was proceeded x_days_ago, if yes, will skip calling\n",
    "                file_skip = to_skip(row[0], \"downloaded_vtresponse\", x_days_ago)\n",
    "                \n",
    "                 # make dir to store API Responses\n",
    "                if not os.path.exists(\"downloaded_vtresponse/\" + dt_string):\n",
    "                    os.makedirs(\"downloaded_vtresponse/\" + dt_string)\n",
    "\n",
    "                #Get an IP address Report\n",
    "                if file_skip == 0:\n",
    "                    r = requests.get(\"https://www.virustotal.com/api/v3/ip_addresses/\"+row[0], headers={\"x-apikey\":API_KEY})\n",
    "                    \n",
    "        #with open(\"downloaded_vtresponse/\" + row[columnIndex] +\".json\", \"w\") as outfile:\n",
    "                    with open(\"downloaded_vtresponse/\" + dt_string + \"/\" + row[columnIndex] + \".json\", \"w\") as outfile:\n",
    "\n",
    "                        outfile.write(r.text)\n",
    "\n",
    "                    output_writer.writerow(row + [datetime.datetime.now()] + [\"Processed\"]) \n",
    "\n",
    "                    outputfile.flush()\n",
    "                    time.sleep(16)\n",
    "\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    output_writer.writerow(row + [datetime.datetime.now()] + [\"Not Processed\"]) \n",
    "                    outputfile.flush()\n",
    "                    \n",
    "                \n",
    "                counter += 1\n",
    "                \n",
    "    print(\"======= process_iplist() END ======= \\n\\n\")\n",
    "#                 time.sleep(16)\n",
    "\n",
    "\n",
    "# check if file exist in folder_to_process during x_days_ago, returns 0 or 1\n",
    "def to_skip(filename, folder_to_process, x_days_ago):\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    dt_string = now.strftime(\"%d%m%Y\")\n",
    "    d = datetime.timedelta(days = x_days_ago)\n",
    "    deducted_date = (now - d).strftime(\"%d%m%Y\")\n",
    "    to_skip = 0\n",
    "\n",
    "    folders = os.listdir(\"downloaded_vtresponse\")\n",
    "    folders = os.listdir(folder_to_process)\n",
    "    \n",
    "\n",
    "    for folder in folders:\n",
    "\n",
    "        if to_skip == 1:\n",
    "            break\n",
    "\n",
    "        # target folders within X days range\n",
    "        if folder >= deducted_date:\n",
    "            files_array = os.listdir(\"downloaded_vtresponse/\" + folder)\n",
    "#                         print(files_array)\n",
    "\n",
    "            for file in files_array:\n",
    "                filename_filetype = file.rsplit('.',1)\n",
    "    #             print(filename_filedate)\n",
    "\n",
    "                ## if filename == target THEN SKIP + WRITE A NOTE\n",
    "                if filename == filename_filetype[0]:\n",
    "                    print(f\"file has been processed on {folder} which is <{x_days_ago} days ago, will skip API call\")\n",
    "                    to_skip = 1\n",
    "                    break\n",
    "        \n",
    "    \n",
    "    return to_skip\n",
    "\n",
    "\n",
    "    #     print(os.listdir(\"downloaded_vtresponse/\"+ folder))    \n",
    "\n",
    "def process_json_folder(folder_to_process,json_template):\n",
    "    \n",
    "    print(\"======= process_json_folder() START =======\")\n",
    "    \n",
    "    # Get Date + Time to input later\n",
    "    now = datetime.datetime.now(pytz.timezone(\"Singapore\"))\n",
    "    dt_string = now.strftime(\"%d%m%Y\")\n",
    "\n",
    "    # Usual Folder: downloaded_vtresponse\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    for filename in os.listdir(folder_to_process):\n",
    "        f = os.path.join(folder_to_process, filename)\n",
    "    \n",
    "#         print(\"f:\", f)\n",
    "        # check if it is a file\n",
    "        if os.path.isfile(f) and f[-5:]==\".json\":\n",
    "\n",
    "            print(\"Processing:\",f)\n",
    "            # Opening JSON file\n",
    "            f = open(f)\n",
    "#             print(f)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "#             print(data)\n",
    "\n",
    "            # load JSON template\n",
    "            new_row = json_template\n",
    "\n",
    "            # populate fields in JSON template\n",
    "            for key in new_row:    \n",
    "#                 print(\"current key\", key)\n",
    "\n",
    "                try:\n",
    "                    current_value = data['data']['attributes'][key]\n",
    "                    \n",
    "                    # replace epoch with legible date format for whois_date and last_analysis_date\n",
    "                    if key[-4:] == \"date\":\n",
    "                        to_zone = tz.gettz('Singapore')\n",
    "                        date_time = datetime.datetime.fromtimestamp( current_value )  \n",
    "#                         current_value = date_time.replace(tzinfo=to_zone)\n",
    "                        date_time.replace(tzinfo=to_zone)\n",
    "                        current_value = date_time\n",
    "                        \n",
    "            \n",
    "                    new_row[key] = current_value\n",
    "\n",
    "                except Exception as e: \n",
    "               \n",
    "                    if key == \"processed_date\":\n",
    "                        new_row[key] = now\n",
    "                        print(\"new_row[key]:\", now)\n",
    "                    \n",
    "                    elif key == \"ip_address\":\n",
    "                        new_row[key] = data['data']['id']\n",
    "                    \n",
    "                    else:\n",
    "                        print(key,\"not found with exception:\",e)\n",
    "\n",
    "            print(\"new_row:\", new_row)\n",
    "            db.ip.insert_one(new_row)\n",
    "\n",
    "            df_result = pd.json_normalize(new_row)\n",
    "            \n",
    "            combined_df = pd.concat([combined_df, df_result], ignore_index=True, sort=False)\n",
    "    \n",
    "    \n",
    "#     print(combined_df)\n",
    "    now = datetime.datetime.now(pytz.timezone(\"Singapore\"))\n",
    "    dt_string = now.strftime(\"%d%m%Y\")\n",
    "    \n",
    "    combined_df.to_csv(folder_to_process + '/' + dt_string + '_parsed-combined.csv')\n",
    "    \n",
    "    print(\"======= process_json_folder() END ======= \\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Process the list of IPs (CSVs ok but IP must be x column in the list)\n",
    "# (filename.csv, column, x_days_ago)\n",
    "process_iplist(\"ip\", 0,7)\n",
    "\n",
    "\n",
    "# Process the downloaded VT JSONs\n",
    "# process_json_folder(\"downloaded_vtresponse_10Jan_combinedFull5k\")\n",
    "process_json_folder(\"downloaded_vtresponse/23022023\",json_template_ip)\n",
    "\n",
    "\n",
    "print(\"completed\")\n",
    "exit(0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bed90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_template_general = {\n",
    "    \n",
    "    \"DNS\": \"\", \n",
    "    \"Whois\": \"\",\n",
    "    \"whois_date\": \"\", ## CONVERT FROM EPOCH TO USER FRIENDLY DATE\n",
    "    \"last_analysis_date\": \"\",\n",
    "    \"creation_date\": \"\",\n",
    "    \"reputation\": \"\",\n",
    "    \"registrar\": \"\",\n",
    "    \"last_analysis_stats\": \"\",  ## SEPERATE INTO 5 COLUMNS?\n",
    "    \"last_https_certificate\": \"\",\n",
    "    \"categories\": \"\",\n",
    "    \"total_votes\": \"\",\n",
    "    \"as_owner\": \"\",\n",
    "    \"country\": \"\",\n",
    "    \"asn\": \"\",\n",
    "    \"download_archived_page\":\"\",\n",
    "    \"image\":\"\",\n",
    "    \"processed_date\":\"\"     ## OWN FIELD TO CHECK X+7 DAYS\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8767b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_template_ip = {\n",
    "    \n",
    "    \"ip_address\": \"\",\n",
    "    \"whois_date\": \"\",\n",
    "    \"last_analysis_date\": \"\",\n",
    "    \"reputation\": \"\",\n",
    "    \"last_analysis_stats\": \"\",\n",
    "    \"total_votes\": \"\",\n",
    "    \"as_owner\": \"\",\n",
    "    \"country\": \"\",\n",
    "    \"asn\": \"\",\n",
    "    \"image\":\"\",\n",
    "    \"processed_date\":\"\"\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af73069",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_template_domain = {\n",
    "    \n",
    "    \"DNS\": \"\", \n",
    "    \"Whois\": \"\",\n",
    "    \"whois_date\": \"\",\n",
    "    \"last_analysis_date\": \"\",\n",
    "    \"creation_date\": \"\",\n",
    "    \"reputation\": \"\",\n",
    "    \"registrar\": \"\",\n",
    "    \"last_analysis_stats\": \"\",\n",
    "    \"last_https_certificate\": \"\",\n",
    "    \"categories\": \"\",\n",
    "    \"total_votes\": \"\",\n",
    "    \"download_archived_page\":\"\",\n",
    "    \"image\":\"\",\n",
    "    \"processed_date\":\"\"\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1707db0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whois_date': 1,\n",
       " 'last_analysis_date': 1,\n",
       " 'reputation': 1,\n",
       " 'last_analysis_stats': 1,\n",
       " 'total_votes': 1,\n",
       " 'as_owner': 1,\n",
       " 'country': 1,\n",
       " 'asn': 1,\n",
       " 'image': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in json_template_ip:\n",
    "    json_template_ip[key] = 1 \n",
    "    \n",
    "json_template_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c31f8920",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mip_address\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open(\"downloaded_vtresponse/22022023/34.123.194.52.json\")\n",
    "data = json.load(f)\n",
    "data['data'].keys()\n",
    "data['data']['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "670b3af1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'34.123.194.52'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%d%m%Y\")\n",
    "    \n",
    "f = open(\"downloaded_vtresponse/22022023/34.123.194.52.json\")\n",
    "\n",
    "new_row = json_template_ip \n",
    "loaded_json = json.load(f)\n",
    "                \n",
    "\n",
    "loaded_json['data']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcfa5a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utc: 2023-02-19 08:53:18\n",
      "sgt: 2023-02-19 08:53:18-07:00\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "epoch_time = 1676767998\n",
    "\n",
    "date_time = datetime.datetime.fromtimestamp( epoch_time )  \n",
    "\n",
    "print(\"utc:\", date_time)\n",
    "\n",
    "to_zone = tz.gettz('Singapore')\n",
    "new_date_time = date_time.replace(tzinfo=to_zone)\n",
    "\n",
    "\n",
    "print(\"sgt:\", new_date_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333cfbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16022023'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd18ff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16022023\n",
      "['22022023_parsed-combined.csv', '34.123.194.52.json', '77.120.241.130.json', '80.253.95.99.json']\n",
      "['22022023', 'parsed-combined.csv']\n",
      "['34.123.194.52.json']\n",
      "['77.120.241.130.json']\n",
      "['80.253.95.99.json']\n",
      "22022023\n",
      "['23022023_parsed-combined.csv', '34.123.194.52.json', '77.120.241.130.json', '80.253.95.99.json']\n",
      "['23022023', 'parsed-combined.csv']\n",
      "['34.123.194.52.json']\n",
      "['77.120.241.130.json']\n",
      "['80.253.95.99.json']\n",
      "23022023\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%d%m%Y\")\n",
    "d = datetime.timedelta(days = 7)\n",
    "a = now - d\n",
    "a = a.strftime(\"%d%m%Y\")\n",
    "a\n",
    "\n",
    "print(a)\n",
    "\n",
    "folders = os.listdir(\"downloaded_vtresponse\")\n",
    "\n",
    "for folder in folders:\n",
    "    if folder >= a:\n",
    "        files_array = os.listdir(\"downloaded_vtresponse/\" + folder)\n",
    "        print(files_array)\n",
    "        \n",
    "        for file in files_array:\n",
    "#             filename_filedate = file.split('_')\n",
    "#             print(filename_filedate)\n",
    "            \n",
    "            ## if filename == target THEN SKIP + WRITE A NOTE\n",
    "\n",
    "        print(folder)\n",
    "        \n",
    "#     print(os.listdir(\"downloaded_vtresponse/\"+ folder))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fabca9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['34.123.194', '52']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"34.123.194.52\"\n",
    "test.rsplit('.',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f3921e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'test')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost',27017)\n",
    "db = client['test']\n",
    "db\n",
    "# db.student.insert({\"Akshay\":500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1a0f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'test'), 'test_collection')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db.test_collection\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ce5b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x2108f0a8af0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.insert_one({\"Test\":\"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8bb9553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 2, 23, 16, 12, 31, 470966, tzinfo=<DstTzInfo 'Singapore' +08+8:00:00 STD>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "now = datetime.datetime.now(pytz.timezone(\"Singapore\"))\n",
    "now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f38762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
